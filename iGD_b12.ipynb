{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iGD: an intergrated genomic data source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, functools, tqdm, PIL\n",
    "import time\n",
    "from multiprocess import Pool\n",
    "import _pickle as pkl\n",
    "\n",
    "#0. Prepare:\n",
    "# file/tile name base: blocksize 2**12=4096 bps\n",
    "fileBase = \"bb12\"         #12 bits block\n",
    "nbp = 4096 \n",
    "nmax = [63748, 62292, 51012, 48924, 46648, 43932, 41008, 37444, 35400, 34432, 34820, 34304, \n",
    "        29164, 27324, 26004, 23304, 21456, 20608, 15256, 16576, 11908, 12932, 39504, 14024]\n",
    "folder = ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', \n",
    "    'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY']\n",
    "gstart = nmax.copy()       #NW without .copy\n",
    "for i in range(1, 24):\n",
    "    gstart[i] += gstart[i-1]\n",
    "gstart.insert(0, 0)\n",
    "nTiles = gstart[24]\n",
    "g2ichr = np.zeros(nTiles, dtype='uint8')\n",
    "for i in range(24):        #convert block index to ichr\n",
    "    g2ichr[gstart[i]:gstart[i+1]] = i\n",
    "#[0, 63748, 126040, 177052, 225976, 272624, 316556, 357564, 395008, 430408, 464840, 499660, 533964,\n",
    "# 563128, 590452, 616456, 639760, 661216, 681824, 697080, 713656, 725564, 738496, 778000, 792024]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create encode_tfbs binary data .igb: store the whole data in a single file\n",
    "def create_igd():   \n",
    "    #1. Read head info\n",
    "    file_path = \"/home/john/LOLA/LOLACore/hg19/encode_tfbs/\"\n",
    "    file = open(file_path+\"index.txt\")\n",
    "    headInfo = pd.read_csv(file, delimiter='\\t')\n",
    "    file.close()\n",
    "    headInfo.to_csv('igdata/igd_index.tsv', sep='\\t')\n",
    "    \n",
    "    #2. Read region data: read int64 default--int32 should be better\n",
    "    file_path += \"regions/\"\n",
    "    file_ids = next(os.walk(file_path))[2]\n",
    "    file_ids.sort()\n",
    "    n_files = len(file_ids)\n",
    "    \n",
    "    count = np.zeros(nTiles, dtype=np.uint32)    \n",
    "    data = np.empty(nTiles, dtype=object)        #bytearray        \n",
    "    for i, id_ in tqdm.tqdm(enumerate(file_ids)):\n",
    "        file = file_path + id_\n",
    "        regionData = pd.read_csv(file, delimiter='\\t', header=None)       \n",
    "        df = regionData.sort_values(by=[0, 1])   #first by str, then by start\n",
    "        n1 = df[1].values//nbp\n",
    "        n2 = df[2].values//nbp-n1 \n",
    "        rchr, ridx, rcnt = np.unique(df[0].values, return_index=True, return_counts=True)        \n",
    "        #if a record crosses the block boundary, list it under both blocks (duplicates)\n",
    "        #the start and end values are kept for fast processing (np): serialization and deserial..\n",
    "        rc1 = df[1].values \n",
    "        rc2 = df[2].values \n",
    "        rc3 = df[4].values \n",
    "        for m in range(0, len(rchr)):\n",
    "            if rchr[m] == 'chrX':\n",
    "                ichr = 22\n",
    "            elif rchr[m] == 'chrY':\n",
    "                ichr = 23\n",
    "            else:\n",
    "                ichr = int(rchr[m][3:])-1\n",
    "            for k in range(0, rcnt[m]):\n",
    "                idx0 = k+ridx[m]\n",
    "                idx = n1[idx0]+gstart[ichr]\n",
    "                #4x4 bytes for fast pack/unpack\n",
    "                rec = struct.pack('IIII', i, rc1[idx0], rc2[idx0], rc3[idx0])          \n",
    "                if n2[idx0] == 0:\n",
    "                    if data[idx]==None:\n",
    "                        data[idx] = rec\n",
    "                    else:\n",
    "                        data[idx] += rec\n",
    "                else:\n",
    "                    for j in range(0,n2[idx0]):\n",
    "                        if data[idx+j]==None:\n",
    "                            data[idx+j] = rec\n",
    "                        else:\n",
    "                            data[idx+j] += rec \n",
    "\n",
    "    #save all in a single file\n",
    "    t0 = time.time()\n",
    "    file = open('igdata/'+fileBase+'.igd', 'wb')\n",
    "    #Write header info: number of struct elements in each tile--nTiles*4\n",
    "    for m in range(nTiles):\n",
    "        if data[m]!=None:\n",
    "            count[m]=len(data[m])\n",
    "        else:\n",
    "            count[m]=0\n",
    "        \n",
    "    file.write(count.tostring())\n",
    "    for m in range(nTiles):\n",
    "        if count[m]>0:\n",
    "            file.write(data[m])       \n",
    "    file.close()\n",
    "    print('t_save=', time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the entire sets: for small igd within memory limit\n",
    "def get_allRegionSets():   \n",
    "    t0 = time.time()\n",
    "    file = open('igdata/' + fileBase + '.igd', 'rb')\n",
    "    data = file.read()\n",
    "    file.close()    \n",
    "    #read head:\n",
    "    i = nTiles*4\n",
    "    count = list(struct.unpack('I'*nTiles, data[0:i]))\n",
    "    #igdata = struct.unpack('IIIH'*nRecords, data[i:]) #NW: due to alighment    \n",
    "    igdata = list(struct.iter_unpack('IIII', data[i:]))   \n",
    "    file.close()          \n",
    "    dt0 = time.time()-t0    \n",
    "    print('time for get_allRegions:', dt0)\n",
    "    return igdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build query set list from bed file: each list of query<-->each igdlist (block)\n",
    "from operator import itemgetter\n",
    "def get_igdlist(file_path):\n",
    "    regionData = pd.read_csv(file_path, delimiter='\\t', header=None)\n",
    "    #regionData.info()\n",
    "    df = regionData.sort_values(by=[0, 1]) \n",
    "    df.reset_index(drop=True, inplace=True)  #df normally keeps the index!   \n",
    "    n1 = df[1].values//nbp\n",
    "    n2 = df[2].values//nbp-n1  \n",
    "    rchr, ridx, rcnt = np.unique(df[0].values, return_index=True, return_counts=True)   \n",
    "    igdlist = []   \n",
    "    for m in range(len(rchr)):\n",
    "        if len(rchr[m])<6:\n",
    "            if rchr[m] == 'chrX':\n",
    "                ichr = 22\n",
    "            elif rchr[m] == 'chrY':\n",
    "                ichr = 23\n",
    "            else:\n",
    "                ichr = int(rchr[m][3:])-1\n",
    "            for k in range(rcnt[m]):\n",
    "                idx0 = k+ridx[m]\n",
    "                idx = n1[idx0] + gstart[ichr]  #to be sorted uniquely\n",
    "                if n2[idx0] == 0:\n",
    "                    igdlist.append((idx, df[1][idx0], df[2][idx0]))\n",
    "                else:\n",
    "                    for j in range(0,n2[idx0]+1): #\n",
    "                        igdlist.append((idx+j,df[1][idx0], df[2][idx0]))                   \n",
    "    igdlist.sort(key=itemgetter(0))\n",
    "    igdlist = np.asarray(igdlist, dtype='uint32')\n",
    "    return igdlist[igdlist[:,0].argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#directly examine each block, attach chr info to the result (add tuple item +(100,))\n",
    "def get_overlaps(igdlist):  \n",
    "    t0 = time.time()     \n",
    "    rblk, ridx, rcnt = np.unique(igdlist[:,0], return_index=True, return_counts=True)  \n",
    "    nblocks = len(rblk)     \n",
    "    file  = open('igdata/' + fileBase + '.igd', 'rb')\n",
    "    len0 = nTiles*4\n",
    "    count = list(struct.unpack('I'*nTiles, file.read(len0))) #bytes of the record\n",
    "    mloc = count.copy()\n",
    "    mloc.insert(0,len0)\n",
    "    for m in range(1, nTiles):\n",
    "        mloc[m] += mloc[m-1] \n",
    "    #-----------------------------------------------------------  \n",
    "    overlaps = []   \n",
    "    for m in range(nblocks):\n",
    "        bk = rblk[m]\n",
    "        if bk<nTiles and count[bk]>0:\n",
    "            ichr = int(g2ichr[bk])   \n",
    "            file.seek(mloc[bk])\n",
    "            regiondb = list(struct.iter_unpack('IIII', file.read(count[bk]))) \n",
    "            #print('nrec:', len(regiondb)) \n",
    "            #--find overlaps in this block\n",
    "            for n in range(rcnt[m]):\n",
    "                idx0 = ridx[m]+n\n",
    "                q, q1, q2 = igdlist[idx0]                    \n",
    "                for item in regiondb:   #list of tuples (234,52312312,52312612,156)\n",
    "                    if not (q2<item[1] or q1>item[2]):\n",
    "                        overlaps.append(item+(ichr,))\n",
    "                        #print(q1, q2, item[1], item[2])\n",
    "    #-----------------------------------------------------------\n",
    "    file.close()\n",
    "    print('nBlocks,', nblocks)\n",
    "    print('time for get_overlaps:', time.time()-t0)\n",
    "    return overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for get_allRegions: 2.5122313499450684\n",
      "13204602\n"
     ]
    }
   ],
   "source": [
    "#0. Create igd:\n",
    "#create_igd()\n",
    "igdata = get_allRegionSets()\n",
    "print(len(igdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nBlocks, 138\n",
      "time for get_overlaps: 0.15026545524597168\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "#0. Create igd:\n",
    "#create_igd()\n",
    "#1. Read a query region set from file\n",
    "file = \"/home/john/LOLA/lola_vignette_data/setC_100.bed\" #test.bed\"#\n",
    "igdlist = get_igdlist(file)\n",
    "#for i in range(len(igdlist)):\n",
    "#    print(i, igdlist[i])\n",
    "overlaps = get_overlaps(igdlist)\n",
    "overlaps = sorted(overlaps, key=itemgetter(0, 4, 1))\n",
    "unilaps = pd.DataFrame(overlaps)[1]\n",
    "unilaps = unilaps.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n",
      "2744\n",
      "2454\n",
      "1 35576437\n",
      "2 45374400\n",
      "3 26021708\n",
      "4 45374459\n",
      "5 26021714\n",
      "6 35576303\n",
      "7 35576503\n",
      "8 15312174\n",
      "9 45374461\n"
     ]
    }
   ],
   "source": [
    "print(len(igdlist))\n",
    "print(len(overlaps))\n",
    "print(len(unilaps))\n",
    "for i in range(1,10):\n",
    "    print(i, unilaps[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
