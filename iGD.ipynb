{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iGD: an intergrated genomic data source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, functools, tqdm, PIL\n",
    "import time\n",
    "from multiprocess import Pool\n",
    "import _pickle as pkl\n",
    "#chr1:  248,956,422+12,151,146-->15,937*16384\n",
    "#chr2:  242,193,529+12,945,965-->15,573\n",
    "#chr3:  198,295,559+10,638,715-->12,753\n",
    "#chr4:  190,214,555+10,165,685-->12,231\n",
    "#chr5:  181,538,259+ 9,519,995-->11,662\n",
    "#chr6:  170,805,979+ 9,130,476-->10,983\n",
    "#chr7:  159,345,973+ 8,613,298-->10,252\n",
    "#chr8:  145,138,636+ 8,221,520--> 9,361\n",
    "#chr9:  138,394,717+ 6,590,811--> 8,850\n",
    "#chr10: 133,797,422+ 7,223,944--> 8,608\n",
    "#chr11: 135,086,622+ 7,535,370--> 8,705\n",
    "#chr12: 133,275,309+ 7,228,129--> 8,576\n",
    "#chr13: 114,364,328+ 5,082,574--> 7,291\n",
    "#chr14: 107,043,718+ 4,865,950--> 6,831\n",
    "#chr15: 101,991,189+ 4,515,076--> 6,501\n",
    "#chr16:  90,338,345+ 5,101,702--> 5,826\n",
    "#chr17:  83,257,441+ 4,614,972--> 5,364\n",
    "#chr18:  80,373,285+ 4,035,966--> 5,152\n",
    "#chr19:  58,617,616+ 3,858,269--> 3,814\n",
    "#chr20:  64,444,167+ 3,439,621--> 4,144\n",
    "#chr21:  46,709,983+ 2,049,697--> 2,977\n",
    "#chr22:  50,818,468+ 2,135,311--> 3,233\n",
    "#chrX:  156,040,895+ 5,753,881--> 9,876\n",
    "#chrY:   57,227,415+   211,643--> 3,506\n",
    "#0. Prepare:\n",
    "# file/tile name base: blocksize 2**14=16384 bps\n",
    "fileBase = \"bb14\"         #14 bits block\n",
    "nmax = [15937, 15573, 12753, 12231, 11662, 10983, 10252, 9361, 8850, 8608, 8705, \n",
    "        8576, 7291, 6831, 6501, 5826, 5364, 5152, 3814, 4144, 2977, 3233, 9876, 3506]\n",
    "folder = ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', \n",
    "    'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY']\n",
    "gstart = nmax.copy()      #NW without .copy\n",
    "for i in range(1, 24):\n",
    "    gstart[i] += gstart[i-1]\n",
    "gstart.insert(0,0)\n",
    "nTiles = gstart[24]\n",
    "#[0, 15937, 31510, 44263, 56494, 68156, 79139, 89391, 98752, 107602, 116210, 124915, 133491, 140782, 147613, \n",
    "# 154114,159940, 165304, 170456, 174270, 178414, 181391, 184624, 194500, 198006]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Append genomic objects to igd file\n",
    "#filename=filebase+chr_+n.igd (n*16384, n>=0) \n",
    "#i: index of the genomic object (eg, ChIP_seq data)\n",
    "def append_index(filebase, igDf):\n",
    "    #igDF is a pandas data frame\n",
    "    igDf.to_csv('igdata/igd_index.tsv', mode='a', sep='\\t', header=False)\n",
    "    return\n",
    "\n",
    "#binary data: 4 times faster than .igd on creating and 10 times faster on retrieval,\n",
    "#also take 25% less space\n",
    "def append_igd(filebase, tmpData):\n",
    "    #open files and apend region data\n",
    "    for ichr in range(1, 25):\n",
    "        ichr1=ichr-1\n",
    "        for m in range(gstart[ichr1], gstart[ichr]):\n",
    "            file = open('igdata/'+folder[ichr]+'/'+fileBase+'_'+str(m-gstart[ichr1])+'.igd', 'a')\n",
    "            file.append(tmpData[ichr1][m])\n",
    "            file.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create encode_tfbs binary data .igb\n",
    "def create_igd():   \n",
    "    #1. Read head info\n",
    "    file_path = \"/home/john/LOLA/LOLACore/hg19/encode_tfbs/\"\n",
    "    file = open(file_path+\"index.txt\")\n",
    "    headInfo = pd.read_csv(file, delimiter='\\t')\n",
    "    file.close()\n",
    "    headInfo.to_csv('igdata/igd_index.tsv', sep='\\t')\n",
    "    \n",
    "    #2. Read region data\n",
    "    file_path += \"regions/\"\n",
    "    file_ids = next(os.walk(file_path))[2]\n",
    "    file_ids.sort()\n",
    "    n_files = len(file_ids)\n",
    "        \n",
    "    tmpd = []\n",
    "    for i in range(0,24):\n",
    "        tmpd.append(np.empty(nmax[i], dtype=object)) #bytearray\n",
    "\n",
    "    for i, id_ in tqdm.tqdm(enumerate(file_ids)):\n",
    "        file = file_path + id_\n",
    "        regionData = pd.read_csv(file, delimiter='\\t', header=None)       \n",
    "        df = regionData.sort_values(by=[0, 1])   #first by str, then by start\n",
    "        n1 = df[1].values//16384\n",
    "        n2 = df[2].values//16384-n1\n",
    "        rchr, ridx, rcnt = np.unique(df[0].values, return_index=True, return_counts=True)        \n",
    "        #if a record crosses the block boundary, list it under both blocks (duplicates)\n",
    "        #the start and end values are kept for fast processing (np): serialization and deserial..\n",
    "        rc1 = df[1].values #.astype('uint32')\n",
    "        rc2 = df[2].values #.astype('uint32')\n",
    "        rc3 = df[4].values #.astype('uint16')\n",
    "        for m in range(0, len(rchr)):\n",
    "            if rchr[m] == 'chrX':\n",
    "                ichr = 22\n",
    "            elif rchr[m] == 'chrY':\n",
    "                ichr = 23\n",
    "            else:\n",
    "                ichr = int(rchr[m][3:])-1\n",
    "            for k in range(0, rcnt[m]):\n",
    "                idx0 = k+ridx[m]\n",
    "                idx = n1[idx0]\n",
    "                rec = struct.pack('IIIH', i, rc1[idx0], rc2[idx0], rc3[idx0]) \n",
    "                if n2[idx0] == 0:\n",
    "                    if tmpd[ichr][idx]==None:\n",
    "                        tmpd[ichr][idx] = rec\n",
    "                    else:\n",
    "                        tmpd[ichr][idx] += rec\n",
    "                else:\n",
    "                    for j in range(0,n2[idx0]):\n",
    "                        if tmpd[ichr][idx+j]==None:\n",
    "                            tmpd[ichr][idx+j] = rec\n",
    "                        else:\n",
    "                            tmpd[ichr][idx+j] += rec            \n",
    "\n",
    "    #save all files\n",
    "    t0 = time.time()\n",
    "    for i in range(0, 24):\n",
    "        for k in range(0, nmax[i]):\n",
    "            file = open('igdata/'+folder[i]+'/'+fileBase+'_'+str(k)+'.igd', 'wb')\n",
    "            #tmp = np.array(tmpd[i][k], dtype=('u4, u4, u4, u2')) \n",
    "            #np.save(file, tmp)#, allow_pickle=False)    \n",
    "            if tmpd[i][k]!=None:\n",
    "                file.write(tmpd[i][k])          \n",
    "            #pkl.dump(tmpd[i][k], file) #, protocol=2)\n",
    "            file.close()\n",
    "    print('t_save=', time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create encode_tfbs binary data .igb: store the whole data in a single file\n",
    "def create_igd_w():   \n",
    "    #1. Read head info\n",
    "    file_path = \"/home/john/LOLA/LOLACore/hg19/encode_tfbs/\"\n",
    "    file = open(file_path+\"index.txt\")\n",
    "    headInfo = pd.read_csv(file, delimiter='\\t')\n",
    "    file.close()\n",
    "    headInfo.to_csv('igdata/igd_index.tsv', sep='\\t')\n",
    "    \n",
    "    #2. Read region data: read int64 default--int32 should be better\n",
    "    file_path += \"regions/\"\n",
    "    file_ids = next(os.walk(file_path))[2]\n",
    "    file_ids.sort()\n",
    "    n_files = len(file_ids)\n",
    "    \n",
    "    count = np.zeros(nTiles, dtype=np.uint32)    \n",
    "    data = np.empty(nTiles, dtype=object)        #bytearray        \n",
    "    for i, id_ in tqdm.tqdm(enumerate(file_ids)):\n",
    "        file = file_path + id_\n",
    "        regionData = pd.read_csv(file, delimiter='\\t', header=None)       \n",
    "        df = regionData.sort_values(by=[0, 1])   #first by str, then by start\n",
    "        n1 = df[1].values//16384\n",
    "        n2 = df[2].values//16384-n1 \n",
    "        rchr, ridx, rcnt = np.unique(df[0].values, return_index=True, return_counts=True)        \n",
    "        #if a record crosses the block boundary, list it under both blocks (duplicates)\n",
    "        #the start and end values are kept for fast processing (np): serialization and deserial..\n",
    "        rc1 = df[1].values #.astype('uint32')\n",
    "        rc2 = df[2].values #.astype('uint32')\n",
    "        rc3 = df[4].values #.astype('uint16')\n",
    "        #rec_bytes = np.array(rc1, dtype=int)\n",
    "        for m in range(0, len(rchr)):\n",
    "            if rchr[m] == 'chrX':\n",
    "                ichr = 22\n",
    "            elif rchr[m] == 'chrY':\n",
    "                ichr = 23\n",
    "            else:\n",
    "                ichr = int(rchr[m][3:])-1\n",
    "            for k in range(0, rcnt[m]):\n",
    "                idx0 = k+ridx[m]\n",
    "                idx = n1[idx0]+gstart[ichr]\n",
    "                #14 bytes\n",
    "                rec = struct.pack('IIIH', i, rc1[idx0], rc2[idx0], rc3[idx0])          \n",
    "                if n2[idx0] == 0:\n",
    "                    if data[idx]==None:\n",
    "                        data[idx] = rec\n",
    "                    else:\n",
    "                        data[idx] += rec\n",
    "                else:\n",
    "                    for j in range(0,n2[idx0]):\n",
    "                        if data[idx+j]==None:\n",
    "                            data[idx+j] = rec\n",
    "                        else:\n",
    "                            data[idx+j] += rec \n",
    "\n",
    "    #save all in a single file: each block should have length of x1024 Bytes\n",
    "    #header: 200,000*(int32 for block starting (x1024), int32 for data length)\n",
    "    #    total 1550*1024=1587200 Bytes, 198006*8=1584048--pad:788*4=3152 bytes\n",
    "    t0 = time.time()\n",
    "    file = open('igdata/'+fileBase+'.igd', 'wb')\n",
    "    #Write header info: (1587200, count*14)\n",
    "    for m in range(nTiles):\n",
    "        if data[m]!=None:\n",
    "            count[m]=len(data[m])\n",
    "        else:\n",
    "            count[m]=0\n",
    "        \n",
    "    file.write(count.tostring())\n",
    "    for m in range(nTiles):\n",
    "        if count[m]>0:\n",
    "            file.write(data[m])       \n",
    "    file.close()\n",
    "    print('t_save=', time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add files to igd\n",
    "def add_GObjs(file_path):\n",
    "    file_ids = next(os.walk(file_path))[2]\n",
    "    file_ids.sort()\n",
    "    n_files = len(file_ids)\n",
    "\n",
    "    tmpd = []\n",
    "    for m in range(0,24):\n",
    "        tmpd.append(np.empty(nmax[m], dtype=object))\n",
    "    for i, id_ in tqdm.tqdm(enumerate(file_ids)):\n",
    "        file = file_path + id_\n",
    "        regionData = pd.read_csv(file, delimiter='\\t', header=None)       \n",
    "        df = regionData.sort_values(by=[0, 1])   #first by str, then by start\n",
    "        n1 = df[1].values//16384\n",
    "        n2 = df[2].values//16384-n1  \n",
    "        rchr, ridx, rcnt = np.unique(df[0].values, return_index=True, return_counts=True)        \n",
    "        #if a record crosses the block boundary, list it under both blocks (duplicates)\n",
    "        #the start and end values are kept for fast processing (np): serialization and deserial..\n",
    "        rc1 = df[1].values #.astype('uint32')\n",
    "        rc2 = df[2].values #.astype('uint32')\n",
    "        rc3 = df[4].values #.astype('uint16')\n",
    "        #rec_bytes = np.array(rc1, dtype=int)\n",
    "        for m in range(0, len(rchr)):\n",
    "            if rchr[m] == 'chrX':\n",
    "                ichr = 22\n",
    "            elif rchr[m] == 'chrY':\n",
    "                ichr = 23\n",
    "            else:\n",
    "                ichr = int(rchr[m][3:])-1\n",
    "            for k in range(0, rcnt[m]):\n",
    "                idx0 = k+ridx[m]\n",
    "                idx = n1[idx0]\n",
    "                #rec = [(i, rc1[idx0], rc2[idx0], rc3[idx0])]    #tuple: a region record\n",
    "                rec = struct.pack('IIIH', i, rc1[idx0], rc2[idx0], rc3[idx0]) \n",
    "                if n2[idx0] == 0:\n",
    "                    if tmpd[ichr][idx]==None:\n",
    "                        tmpd[ichr][idx] = rec\n",
    "                    else:\n",
    "                        tmpd[ichr][idx] += rec\n",
    "                else:\n",
    "                    for j in range(0,n2[idx0]):\n",
    "                        if tmpd[ichr][idx+j]==None:\n",
    "                            tmpd[ichr][idx+j] = rec\n",
    "                        else:\n",
    "                            tmpd[ichr][idx+j] += rec            \n",
    "\n",
    "    #save all files\n",
    "    append_igd(fileBase, tmpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Update igd_whole file (assuming it can't be loaded into memory completely):\n",
    "#load a group of _.igds from sub folders /chr* each time, ... \n",
    "def update_igd_w():\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_read():\n",
    "    #1. test direct access:\n",
    "    t0 = time.time()\n",
    "    total = 0\n",
    "    for m in range(0,24):\n",
    "        cchr = folder[m]\n",
    "        for k in range(0, nmax[m]):\n",
    "            file = open('igdata/'+cchr+'/bb14_'+str(k)+'.igd', 'rb')\n",
    "            data1 = file.read() \n",
    "    dt = time.time()-t0\n",
    "    print('dt2=', dt)\n",
    "\n",
    "    #2. test original data:\n",
    "    t0 = time.time()\n",
    "    file_path = \"/home/john/LOLA/LOLACore/hg19/encode_tfbs/regions/\"\n",
    "    file_ids = next(os.walk(file_path))[2]\n",
    "    total = 0\n",
    "    for i, id_ in tqdm.tqdm(enumerate(file_ids)):\n",
    "        file = open(file_path + id_, 'r')        \n",
    "        df = pd.read_csv(file, delimiter='\\t', header=None) \n",
    "        #data1 = file.read() #readlines()\n",
    "        #total += len(data1)\n",
    "    dt = time.time()-t0\n",
    "    print('dt3=', dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zip_igd():\n",
    "    # test zip file:\n",
    "    #to zip: zip -r igd.zip chr*\n",
    "    t0 = time.time()\n",
    "    import io, zipfile\n",
    "    archive = zipfile.ZipFile('igdata/igd.zip', 'r')\n",
    "    #print(archive.infolist()[1:100])\n",
    "    #print(archive.namelist()[100000:100050]) #infolist()\n",
    "    #time the retrieval process:\n",
    "    for m in range(0,24):\n",
    "        cchr = folder[m]\n",
    "        for k in range(0, nmax[m]):\n",
    "            file = cchr+'/bb14_'+str(k)+'.igd'\n",
    "            data1 = archive.read(file)\n",
    "    archive.close()\n",
    "    #print(len(data1), data1[0:5])\n",
    "    dt = time.time()-t0\n",
    "    print('dt1=', dt)\n",
    "    \n",
    "    #test original\n",
    "    t0 = time.time()\n",
    "    file_path = \"/home/john/LOLA/LOLACore/hg19/encode_tfbs/regions/\"\n",
    "    file_ids = next(os.walk(file_path))[2]\n",
    "    for i, id_ in tqdm.tqdm(enumerate(file_ids)):\n",
    "        regionData = pd.read_csv(file_path+id_, delimiter='\\t', header=None)        \n",
    "        #file = open(file_path + id_, 'r')\n",
    "        #data1 = file.read() #readlines()\n",
    "    dt = time.time()-t0\n",
    "    print('dt2=', dt)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get specified block data: igdlist=[(1, 1008), (1, 3890), (6, 1010), (6, 2000), ....]\n",
    "def get_regions(igdlist):\n",
    "    t0 = time.time()    \n",
    "    nblocks = len(igdlist)\n",
    "    tmpd = []\n",
    "    for m in range(nblocks):\n",
    "        ichr, k = igdlist[m]\n",
    "        file = open('igdata/'+folder[ichr]+'/bb14_'+str(k)+'.igd', 'rb')\n",
    "        tmp = list(struct.iter_unpack('IIIH', file.read()))\n",
    "        tmpd.append(tmp)\n",
    "        file.close()    \n",
    "    print('time for get_regions: ', time.time()-t0) \n",
    "    return tmpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the entire sets\n",
    "def get_allRegionSets():\n",
    "    tmpd = []\n",
    "    for m in range(0,24):\n",
    "        tmpd.append(np.empty(nmax[m], dtype=object))\n",
    "\n",
    "    t0 = time.time()\n",
    "    for m in range(0,24):\n",
    "        cchr = folder[m]\n",
    "        for k in range(0, nmax[m]):\n",
    "            file = open('igdata/'+cchr+'/bb14_'+str(k)+'.igd', 'rb')\n",
    "            tmpd[m][k] = list(struct.iter_unpack('IIIH', file.read()))\n",
    "            file.close()\n",
    "    dt0 = time.time()-t0\n",
    "    \n",
    "    print(dt0)\n",
    "    return tmpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the entire sets\n",
    "def get_allRegionSets_w():   \n",
    "    t0 = time.time()\n",
    "\n",
    "    file = open('igdata/' + fileBase + '.igd', 'rb')\n",
    "    data = file.read()\n",
    "    file.close()\n",
    "    \n",
    "    #read head:\n",
    "    i = nTiles*4\n",
    "    count = list(struct.unpack('I'*nTiles, data[0:i]))\n",
    "    #igdata = struct.unpack('IIIH'*nRecords, data[i:]) #NW: due to alighment    \n",
    "    igdata = list(struct.iter_unpack('IIIH', data[i:]))   \n",
    "    file.close()\n",
    "            \n",
    "    dt0 = time.time()-t0    \n",
    "    print(dt0)\n",
    "    return igdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build query set list from bed file\n",
    "def get_igdlist(file_path):\n",
    "    regionData = pd.read_csv(file, delimiter='\\t', header=None)\n",
    "    #regionData.info()\n",
    "    df = regionData.sort_values(by=[0, 1])\n",
    "    n1 = df[1].values//16384\n",
    "    n2 = df[2].values//16384-n1  \n",
    "    rchr, ridx, rcnt = np.unique(df[0].values, return_index=True, return_counts=True)\n",
    "    igdlist = []\n",
    "    for m in range(len(rchr)):\n",
    "        if rchr[m] == 'chrX':\n",
    "            ichr = 22\n",
    "        elif rchr[m] == 'chrY':\n",
    "            ichr = 23\n",
    "        else:\n",
    "            ichr = int(rchr[m][3:])-1\n",
    "        for k in range(rcnt[m]):\n",
    "            idx0 = k+ridx[m]\n",
    "            idx = n1[idx0]\n",
    "            if n2[idx0] == 0:\n",
    "                igdlist.append((ichr, idx))\n",
    "            else:\n",
    "                for j in range(0,n2[idx0]):\n",
    "                    igdlist.append((ichr, idx+j))\n",
    "    igdlist.sort()\n",
    "    return igdlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find the overlap of query region set with targets in igd: binary projection\n",
    "def get_overlap(query, targets):\n",
    "    t0 = time.time()\n",
    "    #1. binary project or B-tree\n",
    "    \n",
    "    #2. evaluate\n",
    "    \n",
    "    \n",
    "    print('time for get_overlap:', time.time()-t0)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9805734157562256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13202346"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0. Create igd:\n",
    "#create_igd()\n",
    "#igdata = get_allRegionSets()\n",
    "#igdata[0][1]\n",
    "#create_igd_w()\n",
    "igdata = get_allRegionSets_w()\n",
    "len(igdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for get_regions:  0.008287668228149414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(5, 12056296, 12056566, 150),\n",
       " (24, 12056213, 12056637, 152),\n",
       " (32, 12043416, 12043992, 458),\n",
       " (32, 12043622, 12044198, 190),\n",
       " (137, 12056339, 12056555, 274),\n",
       " (174, 12056354, 12056550, 219),\n",
       " (176, 12050438, 12050698, 268),\n",
       " (177, 12050857, 12050955, 575),\n",
       " (178, 12050798, 12051078, 442),\n",
       " (192, 12050548, 12050968, 235),\n",
       " (194, 12050795, 12051095, 357),\n",
       " (196, 12050745, 12051081, 226),\n",
       " (198, 12050788, 12050962, 1000),\n",
       " (202, 12050711, 12050911, 154),\n",
       " (203, 12050786, 12051162, 147),\n",
       " (212, 12044355, 12044679, 173),\n",
       " (213, 12056313, 12056557, 339),\n",
       " (215, 12043516, 12043840, 244),\n",
       " (216, 12043598, 12043842, 205),\n",
       " (218, 12043498, 12043888, 203),\n",
       " (219, 12043600, 12043830, 118),\n",
       " (220, 12043575, 12043792, 569),\n",
       " (221, 12043606, 12043816, 769),\n",
       " (222, 12043602, 12043838, 191),\n",
       " (222, 12057619, 12057855, 159),\n",
       " (223, 12043482, 12043842, 1000),\n",
       " (225, 12043644, 12043783, 779),\n",
       " (226, 12043620, 12043850, 398),\n",
       " (227, 12043636, 12043768, 576),\n",
       " (228, 12043518, 12043924, 1000),\n",
       " (228, 12057617, 12057802, 207),\n",
       " (229, 12043478, 12043904, 744),\n",
       " (230, 12043674, 12043878, 148),\n",
       " (237, 12043558, 12043908, 768),\n",
       " (238, 12043513, 12043913, 139),\n",
       " (240, 12043549, 12043853, 1000),\n",
       " (240, 12057532, 12057896, 366),\n",
       " (242, 12043504, 12043920, 335),\n",
       " (243, 12043561, 12043762, 699),\n",
       " (271, 12052074, 12052314, 220),\n",
       " (426, 12044391, 12044615, 227),\n",
       " (426, 12046035, 12046259, 183),\n",
       " (439, 12050850, 12051186, 134),\n",
       " (440, 12050775, 12051165, 146),\n",
       " (461, 12044390, 12044646, 193),\n",
       " (461, 12046010, 12046266, 260),\n",
       " (467, 12043559, 12043815, 393),\n",
       " (471, 12043561, 12043810, 1000),\n",
       " (476, 12044364, 12044640, 183),\n",
       " (481, 12043531, 12043841, 134),\n",
       " (482, 12043518, 12043858, 101),\n",
       " (484, 12043510, 12043926, 219),\n",
       " (485, 12043460, 12043870, 224),\n",
       " (486, 12043476, 12043860, 715),\n",
       " (487, 12043456, 12043880, 650),\n",
       " (488, 12043452, 12043892, 292),\n",
       " (490, 12043506, 12043862, 320),\n",
       " (491, 12043605, 12043801, 962),\n",
       " (491, 12057590, 12057886, 183),\n",
       " (492, 12056340, 12056580, 237),\n",
       " (497, 12043563, 12043867, 336),\n",
       " (497, 12044125, 12044429, 131),\n",
       " (506, 12043550, 12043830, 321),\n",
       " (510, 12043494, 12043850, 289),\n",
       " (511, 12043562, 12043932, 172),\n",
       " (518, 12043574, 12043890, 577),\n",
       " (519, 12043488, 12043978, 162),\n",
       " (520, 12043902, 12044398, 161),\n",
       " (533, 12043511, 12043861, 108),\n",
       " (538, 12043585, 12043921, 142),\n",
       " (541, 12043592, 12043799, 1000),\n",
       " (541, 12057561, 12057837, 572),\n",
       " (542, 12043530, 12043930, 193),\n",
       " (543, 12043562, 12043898, 508),\n",
       " (548, 12043458, 12043894, 214),\n",
       " (556, 12050454, 12050704, 218),\n",
       " (557, 12050433, 12050683, 191),\n",
       " (574, 12045960, 12046276, 191),\n",
       " (575, 12045926, 12046202, 435),\n",
       " (581, 12043351, 12043955, 188),\n",
       " (581, 12057352, 12057956, 210),\n",
       " (590, 12043383, 12043933, 304),\n",
       " (592, 12043461, 12043857, 202),\n",
       " (596, 12056330, 12056530, 110),\n",
       " (602, 12056340, 12056524, 142),\n",
       " (603, 12056322, 12056526, 237),\n",
       " (604, 12056321, 12056525, 145),\n",
       " (606, 12056315, 12056499, 121),\n",
       " (608, 12056329, 12056493, 131),\n",
       " (611, 12056337, 12056497, 135),\n",
       " (619, 12043638, 12043798, 173),\n",
       " (627, 12056299, 12056489, 163),\n",
       " (634, 12056342, 12056526, 144),\n",
       " (687, 12056271, 12056495, 118)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0. Create igd:\n",
    "#create_igd()\n",
    "#1. Read a query region set from file\n",
    "file = \"/home/john/LOLA/lola_vignette_data/setA_100.bed\"\n",
    "igdlist = get_igdlist(file)\n",
    "tmpd = get_regions(igdlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
