{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iGD: an intergrated genomic data source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, functools, tqdm, PIL\n",
    "import time\n",
    "from multiprocess import Pool\n",
    "import _pickle as pkl\n",
    "#chr1:  248,956,422+12,151,146-->15,937*16384\n",
    "#chr2:  242,193,529+12,945,965-->15,573\n",
    "#chr3:  198,295,559+10,638,715-->12,753\n",
    "#chr4:  190,214,555+10,165,685-->12,231\n",
    "#chr5:  181,538,259+ 9,519,995-->11,662\n",
    "#chr6:  170,805,979+ 9,130,476-->10,983\n",
    "#chr7:  159,345,973+ 8,613,298-->10,252\n",
    "#chr8:  145,138,636+ 8,221,520--> 9,361\n",
    "#chr9:  138,394,717+ 6,590,811--> 8,850\n",
    "#chr10: 133,797,422+ 7,223,944--> 8,608\n",
    "#chr11: 135,086,622+ 7,535,370--> 8,705\n",
    "#chr12: 133,275,309+ 7,228,129--> 8,576\n",
    "#chr13: 114,364,328+ 5,082,574--> 7,291\n",
    "#chr14: 107,043,718+ 4,865,950--> 6,831\n",
    "#chr15: 101,991,189+ 4,515,076--> 6,501\n",
    "#chr16:  90,338,345+ 5,101,702--> 5,826\n",
    "#chr17:  83,257,441+ 4,614,972--> 5,364\n",
    "#chr18:  80,373,285+ 4,035,966--> 5,152\n",
    "#chr19:  58,617,616+ 3,858,269--> 3,814\n",
    "#chr20:  64,444,167+ 3,439,621--> 4,144\n",
    "#chr21:  46,709,983+ 2,049,697--> 2,977\n",
    "#chr22:  50,818,468+ 2,135,311--> 3,233\n",
    "#chrX:  156,040,895+ 5,753,881--> 9,876\n",
    "#chrY:   57,227,415+   211,643--> 3,506\n",
    "#0. Prepare:\n",
    "# file/tile name base: blocksize 2**14=16384 bps\n",
    "fileBase = \"bb14\"         #14 bits block\n",
    "nmax = [15937, 15573, 12753, 12231, 11662, 10983, 10252, 9361, 8850, 8608, 8705, \n",
    "        8576, 7291, 6831, 6501, 5826, 5364, 5152, 3814, 4144, 2977, 3233, 9876, 3506]\n",
    "folder = ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', \n",
    "    'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY']\n",
    "gstart = nmax.copy()       #NW without .copy\n",
    "for i in range(1, 24):\n",
    "    gstart[i] += gstart[i-1]\n",
    "gstart.insert(0, 0)\n",
    "nTiles = gstart[24]\n",
    "g2ichr = np.zeros(nTiles, dtype='uint8')\n",
    "for i in range(24):        #convert block index to ichr\n",
    "    g2ichr[gstart[i]:gstart[i+1]] = i\n",
    "#[0, 15937, 31510, 44263, 56494, 68156, 79139, 89391, 98752, 107602, 116210, 124915, 133491, 140782, 147613, \n",
    "# 154114,159940, 165304, 170456, 174270, 178414, 181391, 184624, 194500, 198006]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Append genomic objects to igd file\n",
    "#filename=filebase+chr_+n.igd (n*16384, n>=0) \n",
    "#i: index of the genomic object (eg, ChIP_seq data)\n",
    "def append_index(filebase, igDf):\n",
    "    #igDF is a pandas data frame\n",
    "    igDf.to_csv('igdata/igd_index.tsv', mode='a', sep='\\t', header=False)\n",
    "    return\n",
    "\n",
    "#binary data: 4 times faster than .igd on creating and 10 times faster on retrieval,\n",
    "#also take 25% less space\n",
    "def append_igd(filebase, tmpData):\n",
    "    #open files and apend region data\n",
    "    for ichr in range(1, 25):\n",
    "        ichr1=ichr-1\n",
    "        for m in range(gstart[ichr1], gstart[ichr]):\n",
    "            file = open('igdata/'+folder[ichr]+'/'+fileBase+'_'+str(m-gstart[ichr1])+'.igd', 'a')\n",
    "            file.append(tmpData[ichr1][m])\n",
    "            file.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create encode_tfbs binary data .igb\n",
    "def create_igd():   \n",
    "    #1. Read head info\n",
    "    file_path = \"/home/john/LOLA/LOLACore/hg19/encode_tfbs/\"\n",
    "    file = open(file_path+\"index.txt\")\n",
    "    headInfo = pd.read_csv(file, delimiter='\\t')\n",
    "    file.close()\n",
    "    headInfo.to_csv('igdata/igd_index.tsv', sep='\\t')\n",
    "    \n",
    "    #2. Read region data\n",
    "    file_path += \"regions/\"\n",
    "    file_ids = next(os.walk(file_path))[2]\n",
    "    file_ids.sort()\n",
    "    n_files = len(file_ids)\n",
    "        \n",
    "    tmpd = []\n",
    "    for i in range(0,24):\n",
    "        tmpd.append(np.empty(nmax[i], dtype=object)) #bytearray\n",
    "\n",
    "    for i, id_ in tqdm.tqdm(enumerate(file_ids)):\n",
    "        file = file_path + id_\n",
    "        regionData = pd.read_csv(file, delimiter='\\t', header=None)       \n",
    "        df = regionData.sort_values(by=[0, 1])   #first by str, then by start\n",
    "        n1 = df[1].values//16384\n",
    "        n2 = df[2].values//16384-n1\n",
    "        rchr, ridx, rcnt = np.unique(df[0].values, return_index=True, return_counts=True)        \n",
    "        #if a record crosses the block boundary, list it under both blocks (duplicates)\n",
    "        #the start and end values are kept for fast processing (np): serialization and deserial..\n",
    "        rc1 = df[1].values #.astype('uint32')\n",
    "        rc2 = df[2].values #.astype('uint32')\n",
    "        rc3 = df[4].values #.astype('uint16')\n",
    "        for m in range(0, len(rchr)):\n",
    "            if rchr[m] == 'chrX':\n",
    "                ichr = 22\n",
    "            elif rchr[m] == 'chrY':\n",
    "                ichr = 23\n",
    "            else:\n",
    "                ichr = int(rchr[m][3:])-1\n",
    "            for k in range(0, rcnt[m]):\n",
    "                idx0 = k+ridx[m]\n",
    "                idx = n1[idx0]\n",
    "                rec = struct.pack('IIII', i, rc1[idx0], rc2[idx0], rc3[idx0]) \n",
    "                for j in range(0,n2[idx0]+1):\n",
    "                    if tmpd[ichr][idx+j]==None:\n",
    "                        tmpd[ichr][idx+j] = rec\n",
    "                    else:\n",
    "                        tmpd[ichr][idx+j] += rec            \n",
    "\n",
    "    #save all files\n",
    "    t0 = time.time()\n",
    "    for i in range(0, 24):\n",
    "        for k in range(0, nmax[i]):\n",
    "            file = open('igdata/'+folder[i]+'/'+fileBase+'_'+str(k)+'.igd', 'wb')\n",
    "            #tmp = np.array(tmpd[i][k], dtype=('u4, u4, u4, u2')) \n",
    "            #np.save(file, tmp)#, allow_pickle=False)    \n",
    "            if tmpd[i][k]!=None:\n",
    "                file.write(tmpd[i][k])          \n",
    "            #pkl.dump(tmpd[i][k], file) #, protocol=2)\n",
    "            file.close()\n",
    "    print('t_save=', time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create encode_tfbs binary data .igb: store the whole data in a single file\n",
    "def create_igd_w():   \n",
    "    #1. Read head info\n",
    "    file_path = \"/home/john/LOLA/LOLACore/hg19/encode_tfbs/\"\n",
    "    file = open(file_path+\"index.txt\")\n",
    "    headInfo = pd.read_csv(file, delimiter='\\t')\n",
    "    file.close()\n",
    "    headInfo.to_csv('igdata/igd_index.tsv', sep='\\t')\n",
    "    \n",
    "    #2. Read region data: read int64 default--int32 should be better\n",
    "    file_path += \"regions/\"\n",
    "    file_ids = next(os.walk(file_path))[2]\n",
    "    file_ids.sort()\n",
    "    n_files = len(file_ids)\n",
    "    \n",
    "    count = np.zeros(nTiles, dtype=np.uint32)    \n",
    "    data = np.empty(nTiles, dtype=object)        #bytearray        \n",
    "    for i, id_ in tqdm.tqdm(enumerate(file_ids)):\n",
    "        file = file_path + id_\n",
    "        regionData = pd.read_csv(file, delimiter='\\t', header=None)       \n",
    "        df = regionData.sort_values(by=[0, 1])   #first by str, then by start\n",
    "        n1 = df[1].values//16384\n",
    "        n2 = df[2].values//16384-n1 \n",
    "        rchr, ridx, rcnt = np.unique(df[0].values, return_index=True, return_counts=True)        \n",
    "        #if a record crosses the block boundary, list it under both blocks (duplicates)\n",
    "        #the start and end values are kept for fast processing (np): serialization and deserial..\n",
    "        rc1 = df[1].values #.astype('uint32')\n",
    "        rc2 = df[2].values #.astype('uint32')\n",
    "        rc3 = df[4].values #.astype('uint16')\n",
    "        #rec_bytes = np.array(rc1, dtype=int)\n",
    "        for m in range(0, len(rchr)):\n",
    "            if rchr[m] == 'chrX':\n",
    "                ichr = 22\n",
    "            elif rchr[m] == 'chrY':\n",
    "                ichr = 23\n",
    "            else:\n",
    "                ichr = int(rchr[m][3:])-1\n",
    "            for k in range(0, rcnt[m]):\n",
    "                idx0 = k+ridx[m]\n",
    "                idx = n1[idx0]+gstart[ichr]\n",
    "                #16 bytes for fast pack/unpack\n",
    "                rec = struct.pack('IIII', i, rc1[idx0], rc2[idx0], rc3[idx0])          \n",
    "                for j in range(0,n2[idx0]+1):\n",
    "                    if data[idx+j]==None:\n",
    "                        data[idx+j] = rec\n",
    "                    else:\n",
    "                        data[idx+j] += rec \n",
    "\n",
    "    #save all in a single file: each block should have length of x1024 Bytes\n",
    "    #header: 200,000*(int32 for block starting (x1024), int32 for data length)\n",
    "    #    total 1550*1024=1587200 Bytes, 198006*8=1584048--pad:788*4=3152 bytes\n",
    "    t0 = time.time()\n",
    "    file = open('igdata/'+fileBase+'.igd', 'wb')\n",
    "    #Write header info: (1587200, count*14)\n",
    "    for m in range(nTiles):\n",
    "        if data[m]!=None:\n",
    "            count[m]=len(data[m]) #in bytes--record length\n",
    "        else:\n",
    "            count[m]=0\n",
    "        \n",
    "    file.write(count.tostring())\n",
    "    for m in range(nTiles):\n",
    "        if count[m]>0:\n",
    "            file.write(data[m])       \n",
    "    file.close()\n",
    "    print('t_save=', time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add files to igd\n",
    "def add_GObjs(file_path):\n",
    "    file_ids = next(os.walk(file_path))[2]\n",
    "    file_ids.sort()\n",
    "    n_files = len(file_ids)\n",
    "\n",
    "    tmpd = []\n",
    "    for m in range(0,24):\n",
    "        tmpd.append(np.empty(nmax[m], dtype=object))\n",
    "    for i, id_ in tqdm.tqdm(enumerate(file_ids)):\n",
    "        file = file_path + id_\n",
    "        regionData = pd.read_csv(file, delimiter='\\t', header=None)       \n",
    "        df = regionData.sort_values(by=[0, 1])   #first by str, then by start\n",
    "        n1 = df[1].values//16384\n",
    "        n2 = df[2].values//16384-n1  \n",
    "        rchr, ridx, rcnt = np.unique(df[0].values, return_index=True, return_counts=True)        \n",
    "        #if a record crosses the block boundary, list it under both blocks (duplicates)\n",
    "        #the start and end values are kept for fast processing (np): serialization and deserial..\n",
    "        rc1 = df[1].values #.astype('uint32')\n",
    "        rc2 = df[2].values #.astype('uint32')\n",
    "        rc3 = df[4].values #.astype('uint16')\n",
    "        #rec_bytes = np.array(rc1, dtype=int)\n",
    "        for m in range(0, len(rchr)):\n",
    "            if rchr[m] == 'chrX':\n",
    "                ichr = 22\n",
    "            elif rchr[m] == 'chrY':\n",
    "                ichr = 23\n",
    "            else:\n",
    "                ichr = int(rchr[m][3:])-1\n",
    "            for k in range(0, rcnt[m]):\n",
    "                idx0 = k+ridx[m]\n",
    "                idx = n1[idx0]\n",
    "                #rec = [(i, rc1[idx0], rc2[idx0], rc3[idx0])]    #tuple: a region record\n",
    "                rec = struct.pack('IIII', i, rc1[idx0], rc2[idx0], rc3[idx0]) \n",
    "                for j in range(0,n2[idx0]+1):\n",
    "                    if tmpd[ichr][idx+j]==None:\n",
    "                        tmpd[ichr][idx+j] = rec\n",
    "                    else:\n",
    "                        tmpd[ichr][idx+j] += rec            \n",
    "\n",
    "    #save all files\n",
    "    append_igd(fileBase, tmpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Update igd_whole file (assuming it can't be loaded into memory completely):\n",
    "#load a group of _.igds from sub folders /chr* each time, ... \n",
    "def update_igd_w():\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_read():\n",
    "    #1. test direct access:\n",
    "    t0 = time.time()\n",
    "    total = 0\n",
    "    for m in range(0,24):\n",
    "        cchr = folder[m]\n",
    "        for k in range(0, nmax[m]):\n",
    "            file = open('igdata/'+cchr+'/bb14_'+str(k)+'.igd', 'rb')\n",
    "            data1 = file.read() \n",
    "    dt = time.time()-t0\n",
    "    print('dt2=', dt)\n",
    "\n",
    "    #2. test original data:\n",
    "    t0 = time.time()\n",
    "    file_path = \"/home/john/LOLA/LOLACore/hg19/encode_tfbs/regions/\"\n",
    "    file_ids = next(os.walk(file_path))[2]\n",
    "    total = 0\n",
    "    for i, id_ in tqdm.tqdm(enumerate(file_ids)):\n",
    "        file = open(file_path + id_, 'r')        \n",
    "        df = pd.read_csv(file, delimiter='\\t', header=None) \n",
    "        #data1 = file.read() #readlines()\n",
    "        #total += len(data1)\n",
    "    dt = time.time()-t0\n",
    "    print('dt3=', dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zip_igd():\n",
    "    # test zip file:\n",
    "    #to zip: zip -r igd.zip chr*\n",
    "    t0 = time.time()\n",
    "    import io, zipfile\n",
    "    archive = zipfile.ZipFile('igdata/igd.zip', 'r')\n",
    "    #print(archive.infolist()[1:100])\n",
    "    #print(archive.namelist()[100000:100050]) #infolist()\n",
    "    #time the retrieval process:\n",
    "    for m in range(0,24):\n",
    "        cchr = folder[m]\n",
    "        for k in range(0, nmax[m]):\n",
    "            file = cchr+'/bb14_'+str(k)+'.igd'\n",
    "            data1 = archive.read(file)\n",
    "    archive.close()\n",
    "    #print(len(data1), data1[0:5])\n",
    "    dt = time.time()-t0\n",
    "    print('dt1=', dt)\n",
    "    \n",
    "    #test original\n",
    "    t0 = time.time()\n",
    "    file_path = \"/home/john/LOLA/LOLACore/hg19/encode_tfbs/regions/\"\n",
    "    file_ids = next(os.walk(file_path))[2]\n",
    "    for i, id_ in tqdm.tqdm(enumerate(file_ids)):\n",
    "        regionData = pd.read_csv(file_path+id_, delimiter='\\t', header=None)        \n",
    "        #file = open(file_path + id_, 'r')\n",
    "        #data1 = file.read() #readlines()\n",
    "    dt = time.time()-t0\n",
    "    print('dt2=', dt)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get specified block data: igdlist=[(1, 1008), (1, 3890), (6, 1010), (6, 2000), ....]\n",
    "# return a list of m lists of tuples: should add chr info \n",
    "def get_regions(igdlist):\n",
    "    t0 = time.time()    \n",
    "    nblocks = len(igdlist)\n",
    "    tmpd = []\n",
    "    for m in range(nblocks):\n",
    "        ichr, k = igdlist[m]\n",
    "        fname = 'igdata/'+folder[ichr]+'/bb14_'+str(k)+'.igd'\n",
    "        if os.path.exists(fname):\n",
    "            file = open(fname, 'rb')\n",
    "            tmp = list(struct.iter_unpack('IIII', file.read()))\n",
    "            tmpd.append(tmp)\n",
    "            file.close()    \n",
    "    print('time for get_regions: ', time.time()-t0) \n",
    "    return tmpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get specified block data: igdlist=[(1, 1008), (1, 3890), (6, 1010), (6, 2000), ....]\n",
    "def get_regions_w(igdlist):\n",
    "    t0 = time.time()    \n",
    "    nblocks = len(igdlist)\n",
    "    tmpd = []\n",
    "    for m in range(nblocks):\n",
    "        ichr, k = igdlist[m]\n",
    "        file = open('igdata/'+folder[ichr]+'/bb14_'+str(k)+'.igd', 'rb')\n",
    "        tmp = list(struct.iter_unpack('IIII', file.read()))\n",
    "        tmpd.append(tmp)\n",
    "        file.close()    \n",
    "    print('time for get_regions: ', time.time()-t0) \n",
    "    return tmpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the entire sets\n",
    "def get_allRegionSets():\n",
    "    tmpd = []\n",
    "    for m in range(0,24):\n",
    "        tmpd.append(np.empty(nmax[m], dtype=object))\n",
    "\n",
    "    t0 = time.time()\n",
    "    for m in range(0,24):\n",
    "        cchr = folder[m]\n",
    "        for k in range(0, nmax[m]):\n",
    "            file = open('igdata/'+cchr+'/bb14_'+str(k)+'.igd', 'rb')\n",
    "            tmpd[m][k] = list(struct.iter_unpack('IIII', file.read()))\n",
    "            file.close()\n",
    "    dt0 = time.time()-t0\n",
    "    \n",
    "    print(dt0)\n",
    "    return tmpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the entire sets\n",
    "def get_allRegionSets_w():   \n",
    "    t0 = time.time()\n",
    "\n",
    "    file = open('igdata/' + fileBase + '.igd', 'rb')\n",
    "    data = file.read()\n",
    "    file.close()\n",
    "    \n",
    "    #read head:\n",
    "    i = nTiles*4\n",
    "    count = list(struct.unpack('I'*nTiles, data[0:i]))\n",
    "    #igdata = struct.unpack('IIIH'*nRecords, data[i:]) #NW: due to alighment    \n",
    "    igdata = list(struct.iter_unpack('IIII', data[i:]))   \n",
    "    file.close()\n",
    "            \n",
    "    dt0 = time.time()-t0    \n",
    "    print(dt0)\n",
    "    return igdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build query set list from bed file: each list of query<-->each igdlist (block)\n",
    "from operator import itemgetter\n",
    "def get_igdlist(file_path):\n",
    "    regionData = pd.read_csv(file_path, delimiter='\\t', header=None)\n",
    "    #regionData.info()\n",
    "    df = regionData.sort_values(by=[0, 1])   #df[i]--ith column not row\n",
    "    df.reset_index(drop=True, inplace=True)  #df normally keeps the index!\n",
    "    n1 = df[1].values//16384\n",
    "    n2 = df[2].values//16384-n1  \n",
    "    rchr, ridx, rcnt = np.unique(df[0].values, return_index=True, return_counts=True)   \n",
    "    igdlist = []   \n",
    "    for m in range(len(rchr)):\n",
    "        if len(rchr[m])<6:\n",
    "            if rchr[m] == 'chrX':\n",
    "                ichr = 22\n",
    "            elif rchr[m] == 'chrY':\n",
    "                ichr = 23\n",
    "            else:\n",
    "                ichr = int(rchr[m][3:])-1\n",
    "            for k in range(rcnt[m]):\n",
    "                idx0 = k+ridx[m]\n",
    "                idx = n1[idx0] + gstart[ichr]  #to be sorted uniquely\n",
    "                for j in range(0,n2[idx0]+1):\n",
    "                    igdlist.append((idx+j,df[1][idx0], df[2][idx0])) \n",
    "    igdlist.sort(key=itemgetter(0))\n",
    "    igdlist = np.asarray(igdlist, dtype='uint32')\n",
    "    return igdlist #sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#directly examine each block, attach chr info to the result (add tuple item +(100,))\n",
    "def get_overlaps(igdlist):\n",
    "    t0 = time.time()  \n",
    "    rblk, ridx, rcnt = np.unique(igdlist[:,0], return_index=True, return_counts=True)  \n",
    "    nblocks = len(rblk)    \n",
    "    overlaps = []\n",
    "    for m in range(nblocks):\n",
    "        bk = rblk[m]\n",
    "        if bk<198006:\n",
    "            ichr = int(g2ichr[bk])\n",
    "            k = bk - gstart[ichr]   \n",
    "            fname = 'igdata/'+folder[ichr]+'/bb14_'+str(k)+'.igd'\n",
    "            if os.path.exists(fname):\n",
    "                file = open(fname, 'rb')\n",
    "                regiondb = list(struct.iter_unpack('IIII', file.read()))\n",
    "                #make it a np array\n",
    "                file.close() \n",
    "                #--find overlaps in this block\n",
    "                for n in range(rcnt[m]):\n",
    "                    idx0 = ridx[m]+n\n",
    "                    q, q1, q2 = igdlist[idx0]\n",
    "                    for item in regiondb:   #list of tuples (234,52312312,52312612,156), (256,52307985,52308160,590)\n",
    "                        if not (q2<item[1] or q1>item[2]):\n",
    "                            overlaps.append(item+(ichr,))\n",
    "\n",
    "    print('nBlocks,', nblocks)\n",
    "    print('time for get_overlaps:', time.time()-t0)\n",
    "    return overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#directly examine each block, attach chr info to the result (add tuple item +(100,))\n",
    "#using np array in the block\n",
    "def get_overlaps_w(igdlist):\n",
    "    t0 = time.time()     \n",
    "    rblk, ridx, rcnt = np.unique(igdlist[:,0], return_index=True, return_counts=True)  \n",
    "    nblocks = len(rblk)     \n",
    "    file  = open('igdata/' + fileBase + '.igd', 'rb')\n",
    "    len0 = nTiles*4\n",
    "    count = list(struct.unpack('I'*nTiles, file.read(len0)))\n",
    "    #print(count[:100])\n",
    "    mloc = count.copy()\n",
    "    #[x*16 for x in mloc]\n",
    "    mloc.insert(0,len0)\n",
    "    for m in range(1, nTiles):\n",
    "        mloc[m] += mloc[m-1] \n",
    "    #-----------------------------------------------------------  \n",
    "    overlaps = []   \n",
    "    for m in range(nblocks):\n",
    "        bk = rblk[m]\n",
    "        if bk<nTiles and count[bk]>0:\n",
    "            ichr = int(g2ichr[bk])   \n",
    "            file.seek(mloc[bk])\n",
    "            regiondb = list(struct.iter_unpack('IIII', file.read(count[bk]))) \n",
    "            #print('nrec:', len(regiondb)) \n",
    "            #--find overlaps in this block\n",
    "            for n in range(rcnt[m]):\n",
    "                idx0 = ridx[m]+n\n",
    "                q, q1, q2 = igdlist[idx0]                    \n",
    "                for item in regiondb:   #list of tuples (234,52312312,52312612,156)\n",
    "                    if not (q2<item[1] or q1>item[2]):\n",
    "                        overlaps.append(item+(ichr,))\n",
    "                        #print(q1, q2, item[1], item[2])\n",
    "    #-----------------------------------------------------------\n",
    "    file.close()\n",
    "    print('nBlocks,', nblocks)\n",
    "    print('time for get_overlaps:', time.time()-t0)\n",
    "    return overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.3692946434021\n",
      "2.575859308242798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13449179"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0. Create igd:\n",
    "#create_igd()\n",
    "igdata = get_allRegionSets()\n",
    "#igdata[0][1]\n",
    "#create_igd_w()\n",
    "igdata = get_allRegionSets_w()\n",
    "len(igdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [    1588 26021603 26022934]\n",
      "1 [    5551 90953248 90954840]\n",
      "2 [    5742 94090603 94091951]\n",
      "3 [     6211 101767799 101769320]\n",
      "4 [     6821 111770653 111771960]\n",
      "5 [     6822 111770653 111771960]\n",
      "6 [     8986 147242999 147244124]\n",
      "7 [     8987 147242999 147244124]\n",
      "8 [     9886 161972829 161974473]\n",
      "9 [    10555 172938552 172939569]\n",
      "nBlocks, 110\n",
      "time for get_overlaps: 0.04926609992980957\n"
     ]
    }
   ],
   "source": [
    "#0. Create igd:\n",
    "#create_igd()\n",
    "#1. Read a query region set from file\n",
    "file = \"/home/john/LOLA/lola_vignette_data/setC_100.bed\" #test.bed\"#\n",
    "igdlist = get_igdlist(file)\n",
    "for i in range(10):\n",
    "    print(i, igdlist[i])\n",
    "overlaps = get_overlaps(igdlist)\n",
    "#overlaps = get_overlaps_w(igdlist)\n",
    "overlaps = sorted(overlaps, key=itemgetter(0, 4, 1))\n",
    "unilaps = pd.DataFrame(overlaps)[1]\n",
    "unilaps = unilaps.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n",
      "2778\n",
      "2455\n",
      "1 (2, 35576437, 35576797, 141, 10)\n",
      "2 (2, 45374400, 45374760, 339, 22)\n",
      "3 (5, 26021708, 26021978, 186, 0)\n",
      "4 (5, 35576437, 35576707, 268, 10)\n",
      "5 (5, 45374459, 45374729, 281, 22)\n",
      "6 (9, 26021714, 26021936, 553, 0)\n",
      "7 (9, 35576303, 35576727, 454, 10)\n",
      "8 (9, 35576503, 35576927, 153, 10)\n",
      "9 (9, 15312174, 15312598, 341, 16)\n"
     ]
    }
   ],
   "source": [
    "print(len(igdlist))\n",
    "print(len(overlaps))\n",
    "print(len(unilaps))\n",
    "for i in range(1,10):\n",
    "    print(i, overlaps[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
