{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iGD: an intergrated genomic data source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, functools, tqdm, PIL\n",
    "import time\n",
    "from multiprocess import Pool\n",
    "import _pickle as pkl\n",
    "import gzip\n",
    "from operator import itemgetter\n",
    "import gc\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "#Divide each HG chromosome into tiles of 16384 (2**14) base pairs\n",
    "#\n",
    "#chr1:  248,956,422+12,151,146-->15,937*16384\n",
    "#chr2:  242,193,529+12,945,965-->15,573\n",
    "#chr3:  198,295,559+10,638,715-->12,753\n",
    "#chr4:  190,214,555+10,165,685-->12,231\n",
    "#chr5:  181,538,259+ 9,519,995-->11,662\n",
    "#chr6:  170,805,979+ 9,130,476-->10,983\n",
    "#chr7:  159,345,973+ 8,613,298-->10,252\n",
    "#chr8:  145,138,636+ 8,221,520--> 9,361\n",
    "#chr9:  138,394,717+ 6,590,811--> 8,850\n",
    "#chr10: 133,797,422+ 7,223,944--> 8,608\n",
    "#chr11: 135,086,622+ 7,535,370--> 8,705\n",
    "#chr12: 133,275,309+ 7,228,129--> 8,576\n",
    "#chr13: 114,364,328+ 5,082,574--> 7,291\n",
    "#chr14: 107,043,718+ 4,865,950--> 6,831\n",
    "#chr15: 101,991,189+ 4,515,076--> 6,501\n",
    "#chr16:  90,338,345+ 5,101,702--> 5,826\n",
    "#chr17:  83,257,441+ 4,614,972--> 5,364\n",
    "#chr18:  80,373,285+ 4,035,966--> 5,152\n",
    "#chr19:  58,617,616+ 3,858,269--> 3,814\n",
    "#chr20:  64,444,167+ 3,439,621--> 4,144\n",
    "#chr21:  46,709,983+ 2,049,697--> 2,977\n",
    "#chr22:  50,818,468+ 2,135,311--> 3,233\n",
    "#chrX:  156,040,895+ 5,753,881--> 9,876\n",
    "#chrY:   57,227,415+   211,643--> 3,506\n",
    "#\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "# file/tile name base: blocksize 2**14=16384 bps\n",
    "fileBase = \"_b14_\"          #14 bits block (tile)\n",
    "nbp = 16384\n",
    "nmax = [15940, 15580, 12760, 12240, 11670, 10990, 10260, 9370, 8860, 8610, 8710, \n",
    "        8580, 7300, 6840, 6510, 5830, 5370, 5160, 3820, 4150, 2980, 3240, 9880, 3510]\n",
    "folder = ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', \n",
    "    'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY']\n",
    "gstart = nmax.copy()       #NW without .copy\n",
    "for i in range(1, 24):\n",
    "    gstart[i] += gstart[i-1]\n",
    "gstart.insert(0, 0)\n",
    "nTiles = gstart[24]        #198160\n",
    "nTiles1 = nTiles-6\n",
    "g2ichr = np.zeros(nTiles, dtype='uint8')\n",
    "for i in range(24):        #convert block index to ichr\n",
    "    g2ichr[gstart[i]:gstart[i+1]] = i\n",
    "#[0, 15940, 31520, 44280, 56520, 68190, 79180, 89440, 98810, 107670, 116280, 124990, 133570, \n",
    "#140870, 147710, 154220, 160050, 165420, 170580, 174400, 178550, 181530, 184770, 194650, 198160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Append genomic object index file (head file)\n",
    "#genomic object: annotation data sets (eg, ChIP_seq data)\n",
    "def append_index(path, dbName, igDf):\n",
    "    #igDF is a pandas data frame\n",
    "    igDf.to_csv(path + '/' + dbName + '_index.tsv', mode='a', sep='\\t', header=False)\n",
    "    return\n",
    "\n",
    "#Append igd data\n",
    "def append_igd(path, dbName, tmpData):\n",
    "    #open files and apend region data\n",
    "    for ichr in range(1, 25):\n",
    "        ichr1=ichr-1\n",
    "        for m in range(gstart[ichr1], gstart[ichr]):\n",
    "            file = open(path+'/'+folder[ichr]+'/'+ dbName +'_'+filebase+'_'+str(m-gstart[ichr1])+'.igd', 'a')\n",
    "            file.append(tmpData[ichr1][m])\n",
    "            file.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a single file igd from bed (.gz) files \n",
    "def create_igd_w(ifilePath, ofilePath, dbName):   \n",
    "    #1. Read head info    \n",
    "    #infilePath = \"/media/john/CE30F6EE30F6DC81/roadmap_sort/\"\n",
    "    file_ids = next(os.walk(ifilePath))[2]\n",
    "    file_ids.sort()\n",
    "    n_files = len(file_ids)  \n",
    "    regionData = pd.read_csv(ifilePath+file_ids[0], delimiter='\\t', header=None) \n",
    "    nrows, ncols = regionData.shape\n",
    "    \n",
    "    #2. Read region data: read int64 default--int32 should be better\n",
    "    nRegions = np.zeros(n_files, dtype='uint32')\n",
    "    mRegion = np.zeros(n_files, dtype='uint32')\n",
    "    count = np.zeros(nTiles, dtype=np.uint32)    \n",
    "    data = np.empty(nTiles, dtype=object)        #bytearray        \n",
    "    for i, id_ in tqdm.tqdm(enumerate(file_ids)):\n",
    "        file = ifilePath + id_\n",
    "        regionData = pd.read_csv(file, delimiter='\\t', header=None)       \n",
    "        df = regionData.sort_values(by=[0, 1])   #first by str, then by start\n",
    "        n1 = df[1].values//nbp\n",
    "        n2 = df[2].values//nbp-n1 \n",
    "        itmp = len(n1)\n",
    "        nRegions[i] = itmp\n",
    "        tmp = np.sum(df[2]-df[1])/itmp    #64-bit\n",
    "        mRegion[i]= int(tmp)\n",
    "        rchr, ridx, rcnt = np.unique(df[0].values, return_index=True, return_counts=True)        \n",
    "        #if a record crosses the block boundary, list it under both blocks (duplicates)\n",
    "        #the start and end values are kept for fast processing (np): serialization and deserial..\n",
    "        rc1 = df[1].values #.astype('uint32')\n",
    "        rc2 = df[2].values #.astype('uint32')\n",
    "        if ncols<5:\n",
    "            rc3 = np.ones(len(df[1]), dtype='uint32')\n",
    "        else:\n",
    "            rc3 = df[4].values #.astype('uint32')\n",
    "        #rec_bytes = np.array(rc1, dtype=int)\n",
    "        for m in range(0, len(rchr)):\n",
    "            ichr = -1\n",
    "            if rchr[m] == 'chrX':\n",
    "                ichr = 22\n",
    "            elif rchr[m] == 'chrY':\n",
    "                ichr = 23\n",
    "            else:\n",
    "                tmps = rchr[m][3:]\n",
    "                if tmps.isdigit():\n",
    "                    ichr = int(tmps)-1\n",
    "            if ichr<24 and ichr>=0:\n",
    "                for k in range(0, rcnt[m]):\n",
    "                    idx0 = k+ridx[m]\n",
    "                    idx = n1[idx0]+gstart[ichr]\n",
    "                    #16 bytes for fast pack/unpack\n",
    "                    rec = struct.pack('IIII', i, rc1[idx0], rc2[idx0], rc3[idx0])          \n",
    "                    for j in range(0,n2[idx0]+1):\n",
    "                        if idx+j<nTiles:\n",
    "                            if data[idx+j]==None:\n",
    "                                data[idx+j] = rec\n",
    "                            else:\n",
    "                                data[idx+j] += rec \n",
    "\n",
    "    #save all in a single file\n",
    "    headInfo = {'File-id':file_ids, 'number_of_regions':nRegions, 'mean_region_size':mRegion}\n",
    "    headInfo = pd.DataFrame(headInfo)\n",
    "    # headInfo.to_csv('igdata/roadmap_index.tsv', sep='\\t')  \n",
    "    headInfo.to_csv(ofilePath+dbName+'_index.tsv', sep='\\t') \n",
    "    #---------------------------------------------------------\n",
    "    t0 = time.time()\n",
    "    file = open(ofilePath+dbName+'_'+fileBase+'.igd', 'wb')\n",
    "    for m in range(nTiles):\n",
    "        if data[m]!=None:\n",
    "            count[m]=len(data[m])/16 # number of struct\n",
    "        else:\n",
    "            count[m]=0\n",
    "       \n",
    "    tmpd = []\n",
    "    for m in range(nTiles):\n",
    "        if count[m]>0:\n",
    "            #to list then sort and then repack\n",
    "            tmpd = list(struct.iter_unpack('IIII', data[m]))\n",
    "            tmpd.sort(key=itemgetter(2))\n",
    "            tmp = bytearray()\n",
    "            for i in range(count[m]):\n",
    "                tmp += struct.pack('IIII', *tmpd[i])           \n",
    "            file.write(tmp) \n",
    "            \n",
    "    #put count[] at the end\n",
    "    file.write(count.tostring())      \n",
    "    file.close()\n",
    "    \n",
    "    print('t_save=', time.time()-t0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get specified block data: igdlist=[(1, 1008), (1, 3890), (6, 1010), (6, 2000), ....]\n",
    "# return a list of m lists of tuples: should add chr info \n",
    "def get_regions(igdlist, dbPath, dbName):\n",
    "    t0 = time.time()    \n",
    "    nblocks = len(igdlist)\n",
    "    tmpd = []\n",
    "    for m in range(nblocks):\n",
    "        ichr, k = igdlist[m]\n",
    "        fname = dbPath +folder[ichr]+'/'+dbName+'_' + fileBase+'_'+str(k)+'.igd'\n",
    "        if os.path.exists(fname):\n",
    "            file = open(fname, 'rb')\n",
    "            tmp = list(struct.iter_unpack('IIII', file.read()))\n",
    "            tmpd.append(tmp)\n",
    "            file.close()    \n",
    "    print('time for get_regions: ', time.time()-t0) \n",
    "    return tmpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get specified block data: igdlist=[(1, 1008), (1, 3890), (6, 1010), (6, 2000), ....]\n",
    "def get_regions_w(igdlist, dbPath, dbName):\n",
    "    t0 = time.time()    \n",
    "    nblocks = len(igdlist)\n",
    "    tmpd = []\n",
    "    for m in range(nblocks):\n",
    "        ichr, k = igdlist[m]\n",
    "        fname = dbPath +folder[ichr]+'/'+dbName+'_' + fileBase+'.igd'\n",
    "        tmp = list(struct.iter_unpack('IIII', file.read()))\n",
    "        tmpd.append(tmp)\n",
    "        file.close()    \n",
    "    print('time for get_regions: ', time.time()-t0) \n",
    "    return tmpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build query set list from bed file: each list of query<-->each igdlist (block)\n",
    "def get_igdlist(file_path):\n",
    "    regionData = pd.read_csv(file_path, delimiter='\\t', header=None)\n",
    "    #regionData.info()\n",
    "    df = regionData.sort_values(by=[0, 1])   #df[i]--ith column not row\n",
    "    df.reset_index(drop=True, inplace=True)  #df normally keeps the index!\n",
    "    n1 = df[1].values//nbp\n",
    "    n2 = df[2].values//nbp-n1  \n",
    "    rchr, ridx, rcnt = np.unique(df[0].values, return_index=True, return_counts=True)   \n",
    "    igdlist = []   \n",
    "    for m in range(len(rchr)):\n",
    "        if len(rchr[m])<6:\n",
    "            if rchr[m] == 'chrX':\n",
    "                ichr = 22\n",
    "            elif rchr[m] == 'chrY':\n",
    "                ichr = 23\n",
    "            else:\n",
    "                ichr = int(rchr[m][3:])-1\n",
    "            for k in range(rcnt[m]):\n",
    "                idx0 = k+ridx[m]\n",
    "                idx = n1[idx0] + gstart[ichr]  #to be sorted uniquely\n",
    "                for j in range(0,n2[idx0]+1):\n",
    "                    igdlist.append((idx+j,df[1][idx0], df[2][idx0])) \n",
    "    igdlist.sort(key=itemgetter(0))\n",
    "    igdlist = np.asarray(igdlist, dtype='uint32')\n",
    "    return igdlist #sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#directly examine each block, attach chr info to the result (add tuple item +(100,))\n",
    "def get_overlaps(igdlist):\n",
    "    t0 = time.time()  \n",
    "    rblk, ridx, rcnt = np.unique(igdlist[:,0], return_index=True, return_counts=True)  \n",
    "    nblocks = len(rblk)    \n",
    "    overlaps = []\n",
    "    for m in range(nblocks):\n",
    "        bk = rblk[m]\n",
    "        if bk<198006:\n",
    "            ichr = int(g2ichr[bk])\n",
    "            k = bk - gstart[ichr]   \n",
    "            fname = 'igdata/'+folder[ichr]+'/bb14_'+str(k)+'.igd'\n",
    "            if os.path.exists(fname):\n",
    "                file = open(fname, 'rb')\n",
    "                regiondb = list(struct.iter_unpack('IIII', file.read()))\n",
    "                #make it a np array\n",
    "                file.close() \n",
    "                #--find overlaps in this block\n",
    "                for n in range(rcnt[m]):\n",
    "                    idx0 = ridx[m]+n\n",
    "                    q, q1, q2 = igdlist[idx0]\n",
    "                    for item in regiondb:   #list of tuples (234,52312312,52312612,156), (256,52307985,52308160,590)\n",
    "                        if not (q2<item[1] or q1>item[2]):\n",
    "                            overlaps.append(item+(ichr,))\n",
    "\n",
    "    print('nBlocks,', nblocks)\n",
    "    print('time for get_overlaps:', time.time()-t0)\n",
    "    return overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#directly examine each block, attach chr info to the result (add tuple item +(100,))\n",
    "#using np array in the block\n",
    "def get_overlaps_w(igdlist, igdName):\n",
    "    t0 = time.time()     \n",
    "    rblk, ridx, rcnt = np.unique(igdlist[:,0], return_index=True, return_counts=True)  \n",
    "    nblocks = len(rblk)     \n",
    "    file  = open('igdata/' + igdName + '.igd', 'rb')\n",
    "    len0 = nTiles*4\n",
    "    count = list(struct.unpack('I'*nTiles, file.read(len0)))\n",
    "    #print(count[:100])\n",
    "    mloc = count.copy()\n",
    "    #[x*16 for x in mloc]\n",
    "    mloc.insert(0,len0)\n",
    "    for m in range(1, nTiles):\n",
    "        mloc[m] += mloc[m-1] \n",
    "    #-----------------------------------------------------------  \n",
    "    overlaps = []   \n",
    "    for m in range(nblocks):\n",
    "        bk = rblk[m]\n",
    "        if bk<nTiles and count[bk]>0:\n",
    "            ichr = int(g2ichr[bk])   \n",
    "            file.seek(mloc[bk])\n",
    "            regiondb = list(struct.iter_unpack('IIII', file.read(count[bk]))) \n",
    "            #print('nrec:', len(regiondb)) \n",
    "            #--find overlaps in this block\n",
    "            for n in range(rcnt[m]):\n",
    "                idx0 = ridx[m]+n\n",
    "                q, q1, q2 = igdlist[idx0]                    \n",
    "                for item in regiondb:   #list of tuples (234,52312312,52312612,156)\n",
    "                    #if not (q2<item[1] or q1>item[2]):\n",
    "                    if q2 >= item[1] and q1 <=item[2]:\n",
    "                        overlaps.append(item+(ichr,))\n",
    "                        #print(q1, q2, item[1], item[2])\n",
    "    #-----------------------------------------------------------\n",
    "    file.close()\n",
    "    print('nBlocks,', nblocks)\n",
    "    print('time for get_overlaps:', time.time()-t0)\n",
    "    return overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1005it [02:35,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_save= 39.84963870048523\n"
     ]
    }
   ],
   "source": [
    "#0. Create igd: path includes '/'\n",
    "ifilePath = \"/media/john/CE30F6EE30F6DC81/roadmap_sort/\"\n",
    "ofilePath = \"/media/john/CE30F6EE30F6DC81/roadmap_igd/\"\n",
    "create_igd_w(ifilePath, ofilePath, \"roadmap\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
